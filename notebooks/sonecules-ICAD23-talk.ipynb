{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "785b42e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c389e134",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['figure.figsize'] = [10, 2]\n",
    "%matplotlib widget\n",
    "import seaborn as sns\n",
    "\n",
    "import sc3nb as scn\n",
    "from pya import Asig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73dbb988",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import sonecules\n",
    "# %run prepare-data.ipynb\n",
    "# sonecules.startup()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a03dcf50",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "### ICAD 2023\n",
    "# sonecules: A Python Sonfication Architecture\n",
    "### Dennis Reinsch and Thomas Hermann\n",
    "#### Ambient Intelligence Group, Bielefeld University, Bielefeld, Germany"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "55d12dd4",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Sonification Process\n",
    "\n",
    "\n",
    "\n",
    "<center>\n",
    "<img src=\"./figures/ecosystem-transpose-process.drawio.svg\" width=100%/>\n",
    "</center>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0a29f1be",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Aproaches to Sonification\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "61ba95aa",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img src=\"figures/Sonecules-Motivation1.png\" width=\"100%\">"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "af523c21",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img src=\"figures/Sonecules-Motivation2.png\" width=\"100%\">"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "dabe6708",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Summary: \n",
    "There are these two extremes:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7389186a",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* (i) open sound synthesis platforms high-jacked for sonification"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "aaf27e0d",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* (ii) all-in-one graphical sonification design programs"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f16e7d03",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* both create a walled garden"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5e697cb4",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "two extrema\n",
    "(i) open sound synthesis platforms high-jacked for sonification\n",
    "- examples: SuperCollider, PureData, Max/MSP, Csound\n",
    "- requires knowledge in regard of sound synthesis to even get started.\n",
    "  something what seems strange when we relate it to visualization\n",
    "- often lack data handling\n",
    "(ii) complex all-in-one graphical sonifi- cation design programs: in this case complete/self-contained pack- ages are provided which often come with GUI, data import func- tions, and one (or few) very specific sonification design(s).\n",
    "- examples: Highcharts Sonification Studio, Sonification Workstation, or Rotator\n",
    "- Such systems are much more beginner-friendly as compared to the above class of approaches,\n",
    "- large code base to integrate the implemented sonification design with specific data loading and processing capabilities and in addition provide a graphical user interface for all this.\n",
    "- but they are quite limited to their specific use case as they are hard (if not impossible) to extend â€“ or even to be adjusted in parameters, if developers did not already offer a control for it.\n",
    "\n",
    "\n",
    "To our opinion, both of these extremes create some kind of walled garden which hinders the sonification community to share their methods and grow\n",
    "We believe that the walls can be teared down by following the example of how computer graphics was made available to users,"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "bd549d01",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Toolchain Solution\n",
    "\n",
    "<center>\n",
    "<img src=\"./figures/ecosystem-transpose.drawio.svg\" width=100%/>\n",
    "</center>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "63a8c9db",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* do one thing but do it well - UNIX principle"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a0dbb3f1",
   "metadata": {},
   "source": [
    "## Sonecules: Getting Started"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b5ba0a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sonecules"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "30483253",
   "metadata": {},
   "source": [
    "Now we startup, which uses the default backend (sc3/ resp. sc3nb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c93aa73a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sonecules.startup()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1a88ce61",
   "metadata": {},
   "source": [
    "* But other backends such as pya are available...\n",
    "\n",
    "Next let's load some data (as pandas Dataframes) to demo our Sonecules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f260553b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run prepare-data.ipynb"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d804c822",
   "metadata": {},
   "source": [
    "* Using mesonic, Sonecules place sonification events in a timeline\n",
    "* A Timeline is played via a playback\n",
    "* Rendering can be realtime or in non-realtime\n",
    "* Let's get our playback to start & stop it"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "841fb76a",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Fundamental Concepts: Context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1ad8356",
   "metadata": {},
   "outputs": [],
   "source": [
    "context = sonecules.gcc()\n",
    "\n",
    "context.reset()                     # empty timeline (aka clear figure)\n",
    "\n",
    "# create a synth\n",
    "s1 = context.synths.create(\"s1\", mutable=False)    \n",
    "\n",
    "# schedule sonic marks\n",
    "with context.at(0.4): s1.start(freq=400, dur=1.6)\n",
    "with context.at(0.6): s1.start(freq=500, dur=1.6)\n",
    "with context.at(0.8): s1.start(freq=600, dur=1.6)\n",
    "\n",
    "context.timeline.plot()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "932393b1",
   "metadata": {},
   "source": [
    "### Fundamental Concept: Playback and Timeline (from mesonic)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "77ade5f5",
   "metadata": {},
   "source": [
    "to play the sonification we need a playback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7206ce85",
   "metadata": {},
   "outputs": [],
   "source": [
    "playback = sonecules.playback()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d33ee931",
   "metadata": {},
   "source": [
    "This can be start(), stop() and we can check and set the time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddeb660c",
   "metadata": {},
   "outputs": [],
   "source": [
    "playback.start()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0047b316",
   "metadata": {},
   "outputs": [],
   "source": [
    "playback.time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14e3d4b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "playback.time = 0.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "747e1cae",
   "metadata": {},
   "outputs": [],
   "source": [
    "playback.stop()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "367fbd70",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "NOTE: Dennis->Thomas"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e50e8723",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Sonecules Demonstration"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d20554b0",
   "metadata": {},
   "source": [
    "* Now we use Sonecules, i.e. capsuled sonification classes\n",
    "* which give a more high-level access to sonification methods\n",
    "* Let's look at \n",
    "  * Audification, \n",
    "  * Buffer-based Mappings: Data modulating sound parameters at high frequencies\n",
    "  * Score-based methods: special versions for Continuous Mappings\n",
    "  * Classical Parameter Mapping Sonifications\n",
    "    * continuous Parameter Mapping Sonification\n",
    "    * discrete Parameter Mapping Sonification\n",
    "  * Model-based Sonification: Data Sonogram\n",
    "  * Earcons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "782eeb2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sonecules\n",
    "sonecules.pb = sonecules.playback\n",
    "context = sonecules.gcc()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "721faa7b",
   "metadata": {},
   "source": [
    "### Audification Sonecule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b55a5c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sonecules.buffersyn import Audification"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "fb7b2951",
   "metadata": {},
   "source": [
    "Let's test with EEG data (of an epileptic seizure).\n",
    "Here is the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff9dc5cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "dasig = Asig(eeg_data, sr=250)\n",
    "plt.figure(); dasig.plot(offset=1, color='r', lw=0.5);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "655cc17c",
   "metadata": {},
   "outputs": [],
   "source": [
    "audification = Audification(data=eeg_data[:,[0,8]], sr=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b3766d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "context.reset()\n",
    "audification.schedule(0, params={\"rate\": 10})\n",
    "sonecules.pb().start()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c54f861c",
   "metadata": {},
   "source": [
    "You can check more parameters of the used synth:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "738b4616",
   "metadata": {},
   "outputs": [],
   "source": [
    "audification.synth.params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e818040",
   "metadata": {},
   "outputs": [],
   "source": [
    "context.reset()\n",
    "audification.schedule(0, params={\"rate\": 20, \"amp\": 0.5, \"pan\": -1})\n",
    "sonecules.pb().start()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "328de901",
   "metadata": {},
   "source": [
    "## Score-based mappings"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "cf14d7e9",
   "metadata": {},
   "source": [
    "Let's load some data for the example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32173055",
   "metadata": {},
   "outputs": [],
   "source": [
    "# take segment at onset of epilepsy, only selected channels, decimate by 5\n",
    "data = Asig(eeg_data, sr=250)[{7.5:10.5}, [0,1,2,5,9,12]][::5]\n",
    "plt.figure(); data.plot(offset=2);"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8d9b6a4f",
   "metadata": {},
   "source": [
    "### Time Variant Oscillator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c2e65b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sonecules.scoresyn import TVOSon\n",
    "\n",
    "snctvo = TVOSon(dasig[{7.5: 10.5}, [1, 2, 3]][::2])\n",
    "\n",
    "context.reset()\n",
    "snctvo.schedule(at=0, rate=1,\n",
    "    base_pitch=60,\n",
    "    pitch_step=12,\n",
    "    pitch_relwid=0.1,\n",
    "    amp_mode=\"change\",\n",
    "    level=-10,\n",
    "    map_mode=\"channelwise\",\n",
    ")\n",
    "sonecules.pb().start(rate=1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "84fc3be0",
   "metadata": {},
   "source": [
    "### Special Case: Polyphonic Sonification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c4c162c",
   "metadata": {},
   "outputs": [],
   "source": [
    "snctvo = TVOSon(dasig[{7.5: 11.5}, [0,1,2,3,4,5]][::2])\n",
    "context.reset()\n",
    "snctvo.schedule(at=0, rate=0.5,\n",
    "    base_pitch=50,\n",
    "    pitch_step=[0,4,7,12,16,19],  # selected musical tones for channels\n",
    "    pitch_relwid=0,  # try 0.5 \n",
    "    amp_mode=\"change\",\n",
    "    level=-5,\n",
    "    map_mode=\"channelwise\",\n",
    ")\n",
    "sonecules.pb().start(rate=1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "928be5db",
   "metadata": {},
   "source": [
    "### Special Case: Timbral Sonification (and more)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f055b4dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# timbral sonification is just a special case of TVOSon\n",
    "snctvo = TVOSon(dasig[{7.5: 10.5}, :][::2])\n",
    "\n",
    "f0 = 60\n",
    "base_pitch = scn.cpsmidi(f0)\n",
    "pitch_steps = [ scn.cpsmidi(f0*(i+1)) - base_pitch for i in range(dasig.channels)] \n",
    "\n",
    "context.reset()\n",
    "snctvo.schedule(at=0, rate=0.3,\n",
    "    base_pitch=base_pitch,\n",
    "    pitch_step=pitch_steps,\n",
    "    pitch_relwid=0,  # use 1.5 for pitch added effect\n",
    "    amp_mode=\"change\",\n",
    "    level=-10,\n",
    "    map_mode=\"channelwise\",\n",
    ")\n",
    "sonecules.pb().start(rate=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c49ba66",
   "metadata": {},
   "outputs": [],
   "source": [
    "sonecules.stop()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "18531c88",
   "metadata": {},
   "source": [
    "This special case works via a score: \n",
    "- each data involves a set event on a synth (sent via OSC)\n",
    "- but alternatively mapping could also be managed by buffers\n",
    "- then each buffer directly modulates the amplitude of an oscillator\n",
    "- For that we can already show a special Sonecule:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "44014a42",
   "metadata": {},
   "source": [
    "### Timbral-Sonification (as own sonecule via buffers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9081624",
   "metadata": {},
   "outputs": [],
   "source": [
    "timbralson = sonecules.buffersyn.TimbralSon(eeg_data[14*256:18*256], sr=256)\n",
    "\n",
    "context.reset()\n",
    "timbralson.schedule(at=0.5, params={\"amp\": 0.05, \"f0\": 120, \"rate\": 0.5})\n",
    "sonecules.pb().start(rate=1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ceb9d96e",
   "metadata": {},
   "source": [
    "- this scales better with high-frequency data (e.g. >1000 changes/second)\n",
    "- a score-based approach would result in issues such as\n",
    "  - python cpu bottleneck\n",
    "  - non-accurate (due to control rate being lower than audio rate)\n",
    "- but this depends on the backend "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a6db5c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "sonecules.stop()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f58b37da",
   "metadata": {},
   "source": [
    "## Classical Parameter Mapping Sonification"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ea87fe1b",
   "metadata": {},
   "source": [
    "There are several ways of doing classical parameter mapping (both discrete and continuous)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e388c5b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sonecules.scoresyn import StandardContinuousPMSon, StandardDiscretePMSon\n",
    "from sc3nb import midicps, linlin"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "842194d2",
   "metadata": {},
   "source": [
    "Let's work with the penguins data set (measures of penguins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9adfcc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "penguins_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24ab8929",
   "metadata": {},
   "outputs": [],
   "source": [
    "# adapting linlin to take dmin dmax as params - names open for discussion\n",
    "dlinlin = lambda value, dmin, dmax, y1, y2: linlin(value, x1=dmin, x2=dmax, y1=y1, y2=y2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "998f4950",
   "metadata": {},
   "outputs": [],
   "source": [
    "# penguins_df[['body_mass_g', 'flipper_length_mm']).plot()\n",
    "sns.pairplot(data=penguins_df, hue=\"species\", x_vars='body_mass_g', y_vars='flipper_length_mm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4525b446",
   "metadata": {},
   "outputs": [],
   "source": [
    "dlinlin = lambda value, dmin, dmax, y1, y2: linlin(value, x1=dmin, x2=dmax, y1=y1, y2=y2)\n",
    "\n",
    "scpmson = StandardContinuousPMSon(\"s2\", \n",
    "    {\"freq\": {\"bounds\": (midicps(30), midicps(90))},  # bounds checking in mesonic is too strict currently\n",
    "     \"amp\": {\"default\": 0.1}}\n",
    ")\n",
    "\n",
    "test_mapping = {\n",
    "    \"onset\": (\"body_mass_g\", dlinlin, {\"y1\": 0, \"y2\": 3}),\n",
    "    \"freq\" : (\"flipper_length_mm\", dlinlin, {\"y1\": midicps(50), \"y2\": midicps(70)})\n",
    "}\n",
    "\n",
    "context.reset() # sn.reset() \n",
    "\n",
    "scpmson.schedule(df=penguins_df, mapping=test_mapping, at=0, stop_after=0.2)\n",
    "# Error message when bounds are not respected by the mapping are currently quite hard to understand\n",
    "# should fix this in mesonic \n",
    "\n",
    "sonecules.playback().start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f764c502",
   "metadata": {},
   "outputs": [],
   "source": [
    "sdpmson = StandardDiscretePMSon(\"s1\", \n",
    "    {\"freq\": {\"bounds\": (midicps(49.9), midicps(70.1))},  # bounds checking in mesonic is too strict currently\n",
    "     \"amp\": {\"default\": 0.1}}\n",
    ")  # bounds are in pre conversion unit - but this is done differently here in the code\n",
    "\n",
    "test_mapping = {\n",
    "    \"onset\": (\"body_mass_g\", dlinlin, {\"y1\": 0, \"y2\": 3}),\n",
    "    \"freq\" : (\"flipper_length_mm\", dlinlin, {\"y1\": midicps(70), \"y2\": midicps(50)})\n",
    "}\n",
    "\n",
    "context.reset() # needed for now as sonecule.reset() does not work yet\n",
    "\n",
    "sdpmson.schedule(df=penguins_df, mapping=test_mapping, at=0, stop_after=0.2)\n",
    "sonecules.playback().start()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "109558e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "context.timeline"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3ed7b07a",
   "metadata": {},
   "source": [
    "### Continuous Parameter Mapping with specifying a callback function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53b30651",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sonecules.scoresyn import CPMSonCB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d19c4298",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(); Asig(bld_df.iloc[:24*7, 8:].values, sr=24).plot(offset=1); plt.grid(); plt.title(\"Building Dataset\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4570dce2",
   "metadata": {},
   "outputs": [],
   "source": [
    "scb = CPMSonCB(bld_df.iloc[:7*24, 6:])  # one week\n",
    "# scb = CPMSonCB(bld_df.iloc[:4000, 7:])  # whole dataset\n",
    "\n",
    "mapcol = scb.mapcol\n",
    "\n",
    "def callback_fn(r, cmi, cma, pp):\n",
    "    pp['freq']      = scn.midicps(mapcol(r, 'temperature', cmi, cma, 48, 72))\n",
    "    pp['amp']       = scn.dbamp(mapcol(r, 'humidity', cmi, cma, -20, 0)) \n",
    "    pp['pan']       = mapcol(r, 'hc_wb_electrical', cmi, cma, -1, 1)\n",
    "    pp['numharm']   = mapcol(r, 'solar_radiation', cmi, cma, 1, 12)\n",
    "    pp['vibfreq']   = scn.linlin(r['hc_wb_hot_water'], -0.5, 0.5, 3, 8)\n",
    "    pp['vibintrel'] = 0\n",
    "    return pp\n",
    "\n",
    "context.reset()\n",
    "scb.schedule(at=0, duration=4, callback_fn=callback_fn)\n",
    "sonecules.playback().start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3be8799",
   "metadata": {},
   "outputs": [],
   "source": [
    "scb.create_callback_template(auto_assign=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4e7d2c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cbfn(r, cmi, cma, pp):\n",
    "    # columns are:'sunday' 'hour_from_noon' 'hour' 'am_pm' \n",
    "    # 'temperature' 'humidity' 'solar_radiation' 'wind_speed' \n",
    "    # 'hc_wb_electrical' 'hc_wb_cold_water' 'hc_wb_hot_water' \n",
    "    pp['freq']     \t = mapcol(r, 'sunday', cmi, cma, 123.48568035539805, 246.9713607107961)\n",
    "    pp['amp']      \t = mapcol(r, 'hour_from_noon', cmi, cma, 0.41876930734447715, 0.8375386146889543)\n",
    "    pp['vibintrel']\t = 0 \n",
    "    pp['numharm']  \t = mapcol(r, 'solar_radiation', cmi, cma, 1, 5)\n",
    "    pp['pint']     \t = 0\n",
    "    pp['pan']      \t = mapcol(r, 'hc_wb_electrical', cmi, cma, -0.3400964812712826, -0.6801929625425652)\n",
    "\n",
    "# create sonification e.g. by using\n",
    "context.reset()\n",
    "scb.schedule(at=0, duration=5, callback_fn=callback_fn)\n",
    "sonecules.playback().start(rate=1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "355c9cb5",
   "metadata": {},
   "source": [
    "NOTE: Thomas->Dennis"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b5a7a6b4",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Trigger Sonifications\n",
    "\n",
    "TODO! Earcons - Event-based Sonification of mathematical function (TH)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "52d448f0",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Model-Based Sonification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06e71892",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sonecules.triggersyn import DataSonogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47cd1d19",
   "metadata": {},
   "outputs": [],
   "source": [
    "sonecules.reset()\n",
    "sonecules.gcc().enable_realtime()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4fe675d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dsg2 = DataSonogram(penguins_df, x=\"flipper_length_mm\", y=\"bill_length_mm\", label=\"species\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ca1aced4",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "## Roadmap for Demos of Sonifications for the ICAD paper\n",
    "\n",
    "coarse line of thought for unfolding sonecules: from ANALOGIC -> MAPPING -> MODELS -> SYMBOLS (Earcons, Parameterized Auditory Icons)\n",
    " \n",
    "Buffer\n",
    "- Audification (BUFFER HOLDS DATA)\n",
    "  - schedule\n",
    "- Interactive Audification --> Widgets\n",
    "  - create --> macht GUI\n",
    "- Data Modulated Continuous Mappings: (HF Control Data->Parameters)\n",
    "- Continuous Mapping using Buffers (audification near)\n",
    "- Timbral Sonification (using Buffers) \n",
    "- TVOSC\n",
    "\n",
    "Score\n",
    "- TVOSC  --> dabei neu: MUTABLE\n",
    "  - Graphical interface?\n",
    "- CPMSon --> 1 synth, multiple parameter \n",
    "  - (freq, amp, pan, vibr (F/I), numharm, pulse rate)\n",
    "- Classical good old DPMSon\n",
    "- iris/penguin/buildung/glass\n",
    "\n",
    "Event\n",
    "- Event with all data lookahead (condition function)\n",
    "- Event bekommt Stream und processed on the run\n",
    "- Model-based Sonification\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "24f9184c",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Goals"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "149101e4",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## flexibility and portability\n",
    "  \n",
    "* build with Python\n",
    "* allows adding new backends\n",
    "* platform- and backend independent\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "251c4929",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## availability and distribution\n",
    "\n",
    "* sonifications as reusable units\n",
    "* growing collection"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0eb3afe3",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## reproducibility\n",
    "\n",
    "* shared as actual sonification not as sound file\n",
    "* experienceable with different data and parameters"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "240f7bbd",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## benchmarking\n",
    "\n",
    "* enables comparisons between sonification designs\n",
    "* enchancing scientific standards and development"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "db91578b",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## dissemination\n",
    "\n",
    "* spreading sonifications as quickly usable tools\n",
    "* reaching and enabling people without sonification expertise"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "650b4bac",
   "metadata": {},
   "source": [
    "# Conclusion"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f3afa0b8",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# ---\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "fbca032b",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Sonification Pipeline - All in One\n",
    "\n",
    "<center>\n",
    "<img src=\"./figures/soni-pipeline-allinone-small.jpg\"/>\n",
    "</center>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "cb931af7",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "IN: The first example are tools that offer the user to handle the complete pipeline\n",
    "\n",
    "However the resulting tools are often very specialized towards certain tasks and often can be regarded  as a graphical user interface for a single sonification design.\n",
    "\n",
    "This does not allow the user to create completely new sonifications as the tools are not flexible enough, but rather use a certain sonification without much effort.\n",
    "\n",
    "\n",
    "OUT: This is why many sonification experts prefer to built their own custom tools"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d98f8e64",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Sonification Pipeline - Combination of Tools\n",
    "\n",
    "<center>\n",
    "<img src=\"./figures/soni-pipeline-combi-small.jpg\"/>\n",
    "</center>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2f6c7f02",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* sc3nb = Python + SuperCollder in Jupyter notebooks"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "697bcac7",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "IN: A common approach here is to use a sound synthesis engine like SuperCollider for creating the sound \n",
    "\n",
    "the data is prepared beforehand with other tools like Python.\n",
    "\n",
    "\n",
    "While this approach offers the user a more flexible way it still requires the user to have knowledge about used sound synthesis engine\n",
    "\n",
    "\n",
    "additionally it often becomes complicated to mix and match the different tools with each other and share the data\n",
    "\n",
    "\n",
    "\n",
    "To tackle this problem we already created sc3nb which makes SuperCollider accessible from Python and allows the combined usage in one interactive Jupyter notebook\n",
    "\n",
    "However sc3nb is strictly tied to SuperCollider and requires that the user is familiar with SuperCollider \n",
    "\n",
    "\n",
    "OUT: "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6ff67cce",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# mesonic\n",
    "\n",
    "<center>\n",
    "<img src=\"./figures/mesonic-pipeline.jpg\"/>\n",
    "</center>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2f90ca79",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "IN: mesonic wants to go further by more directly focusing on the transformation.\n",
    "\n",
    "this is done by providing a meso level that should be more flexible than high level (all in one) approaches \n",
    "\n",
    "but it should still offer the user an a shortcut to create new sonifications designs\n",
    "\n",
    "instead of requiring the creation of custom tools, which are often hard to share and maintain\n",
    "\n",
    "and require the user to deeply dive down into sound synthesis engines.\n",
    "\n",
    "While at least some knowledge about sound synthesis is required to create a sonification it should be noted that the\n",
    "most sound synthesis tools are quite complex and can be intimidating for new users that want create a new sonification\n",
    "\n",
    "Additionally it is important to note that most sound synthesis engines are not specifically crafted for sonifications and often lack data processing capabilities.\n",
    "\n",
    "OUT: The idea to introduce a layer in between the low level sound synthesis world and the high level sonification applications is inspired by the visualization domain\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e7c5f6be",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# matplotlib\n",
    "\n",
    "<center>\n",
    "<img src=\"./figures/anatomy-of-figure.jpg\"/>\n",
    "</center>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "16b9c360",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "IN: If we look at matplotlib f.e. it becomes obvious that .. \n",
    "\n",
    "the plots does consists of different objects\n",
    "\n",
    "These objects together form the complete plot \n",
    "\n",
    "As a user I do not need to create every single linie\n",
    "but i can create complex plots by single function calls that will provide me all the single objects\n",
    "\n",
    "Additionally it is possible to fine tune the plot using a object oriented approach.\n",
    "and adjust f.e. the limits and the title.\n",
    "\n",
    "This is what makes matplotlib easy to use but still a flexible basis for many other applications.\n",
    "\n",
    "OUT: mesonic tries to adapt this idea to form a sonification from single parts and other ideas from the visualization domain into the domain of sonification\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e3192edf",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# mesonic - audio objects\n",
    "\n",
    "<center>\n",
    "<img src=\"./figures/mesonic-synth.jpg\"/>\n",
    "</center>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3531b0c5",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* practical use: discrete vs continuous Parameter Mapping Sonification"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9e2e9838",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* inspired by Enge et al. 2021 - **0D / 1D auditory mark**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "057cfbcd",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# mesonic - audio objects\n",
    "\n",
    "<center>\n",
    "<img src=\"./figures/mesonic-buffer-record.jpg\"/>\n",
    "</center>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7f5a41fb",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fffaccec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mesonic\n",
    "import numpy as np\n",
    "from pya import *\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "from sc3nb import linlin, midicps, cpsmidi\n",
    "import sc3nb as scn"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "40dc540e",
   "metadata": {},
   "source": [
    "Lets start by preparing mesonic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1e2bd81",
   "metadata": {},
   "outputs": [],
   "source": [
    "context = mesonic.create_context()\n",
    "context.enable_realtime();\n",
    "context.processor.latency = 0.05\n",
    "context.processor.latency"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "82b90ab6",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "In this example we will use the EEG data from the [Supplementary material for \"sc3nb: a Python-SuperCollider Interface for Auditory Data Science\"](https://doi.org/10.4119/unibi/2956379)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10f50fa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.loadtxt(\"./files/epileptic-eeg.csv\", delimiter=\",\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6726788c",
   "metadata": {},
   "source": [
    "We can simply create a stereo Buffer using this data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5871a45d",
   "metadata": {},
   "outputs": [],
   "source": [
    "buf = context.buffers.from_data(data[:,[0,1]], sr=256)\n",
    "buf"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d7037344",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "And create a default Synth to play it back"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecd65006",
   "metadata": {},
   "outputs": [],
   "source": [
    "bsyn = context.synths.from_buffer(buf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5238efd",
   "metadata": {},
   "outputs": [],
   "source": [
    "bsyn # to see the synth's controls"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8dea05b1",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "let's audify the data in a loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f2ff942",
   "metadata": {},
   "outputs": [],
   "source": [
    "bsyn.start(rate=20, amp=0.1, loop=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbe18e8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "bsyn.rate = 5\n",
    "bsyn.amp = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8991b22",
   "metadata": {},
   "outputs": [],
   "source": [
    "bsyn.stop()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3daab587",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "A more advanced example using Granular Synthesis for interactive scrubbing of the buffer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b80235e",
   "metadata": {},
   "outputs": [],
   "source": [
    "context.synths.buffer_synthdefs[\"tgrains\"]= r\"\"\"\n",
    "{ | bufnum={{BUFNUM}}, amp=0.3, rate=10, trate=5, pos=0 |\n",
    "    var dur, cpos, sig;\n",
    "    dur = 4 / trate;\n",
    "    cpos = pos * BufDur.kr(bufnum);\n",
    "    sig = TGrains.ar(2, Impulse.ar(trate), bufnum, rate, cpos, dur, 0, 0.5, 2);\n",
    "    Out.ar(0, sig * amp);\n",
    "}\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7261c7e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "buf = context.buffers.from_data(data[:,5], sr=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "033c686a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tgsyn = context.synths.from_buffer(buf, synth_name=\"tgrains\")\n",
    "tgsyn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dc0c5b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "tgsyn.start(rate=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a422ea14",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib qt\n",
    "fig, ax = plt.subplots(figsize=(8,2))\n",
    "asig = Asig(data[:,5], sr=256).plot()\n",
    "\n",
    "def on_move(event):\n",
    "    if event.inaxes and event.button is mpl.backend_bases.MouseButton.LEFT:\n",
    "        tgsyn.rate =  20 if event.ydata > 0 else 50\n",
    "        tgsyn.pos = linlin(event.xdata, 0, 50, 0, 1)\n",
    "\n",
    "binding_id = fig.canvas.mpl_connect('motion_notify_event', on_move)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71b8a400",
   "metadata": {},
   "outputs": [],
   "source": [
    "tgsyn.stop()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c8a877c2",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# mesonic concepts\n",
    "\n",
    "<center>\n",
    "<img src=\"./figures/mesonic-concepts.jpg\"/>\n",
    "</center>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d99d0ccc",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "Here you can see an overview of the concepts used in mesonic\n",
    "\n",
    "- the Context can be regarded as counterpart of the Figure from matplotlib and as the central interface\n",
    "    - it controls the backend which is clearly separated and designed to be exchangeable\n",
    "\n",
    "- The Backend provides different Managers to create the Audio Objects\n",
    "- and is also responsible for creating the Audio Object EventHandlers that will create sound in the backend \n",
    "\n",
    "\n",
    "- The Audio Objects  are the available building blocks for the sonification which are inspired by common concepts from sound synthesis software\n",
    "- The different objects offer actions like f.e. starting a Synth with a certain frequency\n",
    "These however do not directly generate sounds but rather create Events \n",
    "\n",
    "The events are then passed to the Context which\n",
    "provides the sonification time for the event.\n",
    "The Event then will be inserted into the timeline as a bundles \n",
    "\n",
    "The Timeline then forms a data structure that contains all the actions from the sonification\n",
    "\n",
    "To actually listen to the sonification the events in the timeline can be rendered offline or by the playback\n",
    "\n",
    "The playback offers an interactive control over the sonification and allows f.e. filtering by data source via the BundleProcessor\n",
    "before passing the events to the Audio Object EventHandler in the Backend \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60b56460",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a0ce605",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fcee152",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "print(context.synths.buffer_synthdefs[\"playbuf\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "343df2de",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "context.timeline.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a4b9184",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
