{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "785b42e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c389e134",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['figure.figsize'] = [10, 2]\n",
    "%matplotlib widget\n",
    "import seaborn as sns\n",
    "\n",
    "import sc3nb as scn\n",
    "from pya import Asig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73dbb988",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sonecules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25c81c11",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run prepare-data.ipynb"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a03dcf50",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "### ICAD 2023\n",
    "# sonecules: A Python Sonfication Architecture\n",
    "### Dennis Reinsch and Thomas Hermann\n",
    "#### Ambient Intelligence Group, Bielefeld University, Bielefeld, Germany"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b282fe71",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Why sonecules?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "61ba95aa",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img src=\"figures/Sonecules-Motivation1.png\" width=\"100%\">"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "af523c21",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img src=\"figures/Sonecules-Motivation2.png\" width=\"100%\">"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "bd549d01",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# sonecules: Toolchain Solution\n",
    "\n",
    "<center>\n",
    "<img src=\"./figures/ecosystem-transpose.drawio.svg\" width=100%/>\n",
    "</center>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "bd33c4a5",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- inspired by chemistry: where molecules are combinations of atoms\n",
    "- Likewise sonecules are combinations of single parts"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a0dbb3f1",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Sonecules: Getting Started"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b5ba0a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sonecules"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "30483253",
   "metadata": {},
   "source": [
    "Now we startup, which uses the default backend (sc3/ resp. sc3nb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c93aa73a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sonecules.startup()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1a88ce61",
   "metadata": {},
   "source": [
    "Next let's load some data (as pandas Dataframes) to demo our Sonecules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f260553b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run prepare-data.ipynb"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "841fb76a",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Fundamental Concepts: Context and Timeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1ad8356",
   "metadata": {},
   "outputs": [],
   "source": [
    "context = sonecules.gcc()\n",
    "\n",
    "# create a synth\n",
    "s1 = context.synths.create(\"s1\", mutable=False)    \n",
    "\n",
    "# schedule sonic marks\n",
    "with context.at(0.4): s1.start(freq=400, dur=0.2)\n",
    "with context.at(0.6): s1.start(freq=500, dur=1.0)\n",
    "with context.at(0.8): s1.start(freq=600, dur=1.0)\n",
    "\n",
    "context.timeline.plot()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "932393b1",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Fundamental Concepts: Playback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53f52702",
   "metadata": {},
   "outputs": [],
   "source": [
    "context.timeline.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7206ce85",
   "metadata": {},
   "outputs": [],
   "source": [
    "playback = sonecules.playback()  # used as media player"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddeb660c",
   "metadata": {},
   "outputs": [],
   "source": [
    "playback.start()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0047b316",
   "metadata": {},
   "outputs": [],
   "source": [
    "playback.time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14e3d4b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "playback.time = 0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "747e1cae",
   "metadata": {},
   "outputs": [],
   "source": [
    "playback.stop()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e50e8723",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Sonecules Demonstration"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d20554b0",
   "metadata": {},
   "source": [
    "* Now we use Sonecules, i.e. capsuled sonification classes\n",
    "* which give a more high-level access to sonification methods\n",
    "* Let's look at \n",
    "  * Audification\n",
    "  * Data modulating sound parameters at high frequencies\n",
    "  * Time-Variant Oscillators as Continuous Mappings \n",
    "  * Standard Discrete and Continuous Parameter Mapping Sonifications\n",
    "  * Model-based Sonification: Data Sonogram"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "721faa7b",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Audification Sonecule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b55a5c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sonecules.buffersyn import Audification"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "fb7b2951",
   "metadata": {},
   "source": [
    "Let's test with EEG data (of an epileptic seizure).\n",
    "Here is the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff9dc5cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "dasig = Asig(eeg_data, sr=250)\n",
    "plt.figure(); dasig.plot(offset=1, color='r', lw=0.5);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "655cc17c",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "audification = Audification(data=eeg_data[:,[0,8]], sr=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b3766d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "context.clear()\n",
    "audification.schedule(0, params={\"rate\": 7})\n",
    "playback.start()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c54f861c",
   "metadata": {},
   "source": [
    "You can check more parameters of the used synth:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "738b4616",
   "metadata": {},
   "outputs": [],
   "source": [
    "audification.synth.params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e818040",
   "metadata": {},
   "outputs": [],
   "source": [
    "context.clear()\n",
    "audification.schedule(0, params={\"rate\": 20, \"amp\": 0.5, \"pan\": 0.75})\n",
    "playback.start()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "328de901",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Score-based mappings"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "cf14d7e9",
   "metadata": {},
   "source": [
    "Let's select some data for the example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32173055",
   "metadata": {},
   "outputs": [],
   "source": [
    "# take segment at onset of epilepsy, only selected channels, decimate by 5\n",
    "data = Asig(eeg_data, sr=250)[{7.5:10.5}, [0,1,2,5,9,12]][::5]\n",
    "plt.figure(); data.plot(offset=2);"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8d9b6a4f",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Time Variant Oscillator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c2e65b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sonecules.scoresyn import TVOSon\n",
    "\n",
    "snctvo = TVOSon(dasig[{7.5: 10.5}, [1, 2, 3]][::2])\n",
    "\n",
    "context.clear()\n",
    "snctvo.schedule(at=0, rate=4,\n",
    "    base_pitch=60,\n",
    "    pitch_step=12,\n",
    "    pitch_relwid=3,\n",
    "    amp_mode=\"change\",\n",
    "    level=-10,\n",
    "    map_mode=\"channelwise\",\n",
    ")\n",
    "playback.start(rate=1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "84fc3be0",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Special Case: Polyphonic Sonification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c4c162c",
   "metadata": {},
   "outputs": [],
   "source": [
    "snctvo = TVOSon(dasig[{7.5: 11.5}, [0,1,2,3,4,5]][::2])\n",
    "context.clear()\n",
    "snctvo.schedule(at=0, rate=0.5,\n",
    "    base_pitch=50,\n",
    "    pitch_step=[0,4,7,12,16,19],  # selected musical tones for channels\n",
    "    pitch_relwid=0.0,  # try 0.5 \n",
    "    amp_mode=\"change\",\n",
    "    level=-5,\n",
    "    map_mode=\"channelwise\",\n",
    ")\n",
    "playback.start(rate=1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "928be5db",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Special Case: Timbral Sonification (and more)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f055b4dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# timbral sonification is just a special case of TVOSon\n",
    "snctvo = TVOSon(dasig[{7.5: 9.5}, :][::2])\n",
    "\n",
    "f0 = 60\n",
    "base_pitch = scn.cpsmidi(f0)\n",
    "pitch_steps = [ scn.cpsmidi(f0*(i+1)) - base_pitch for i in range(dasig.channels)] \n",
    "\n",
    "context.clear()\n",
    "snctvo.schedule(at=0, rate=0.3,\n",
    "    base_pitch=base_pitch,\n",
    "    pitch_step=pitch_steps,\n",
    "    pitch_relwid=0,  # use 1.5 for pitch added effect\n",
    "    amp_mode=\"change\",\n",
    "    level=-10,\n",
    "    map_mode=\"channelwise\",\n",
    ")\n",
    "playback.start(rate=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c49ba66",
   "metadata": {},
   "outputs": [],
   "source": [
    "sonecules.stop()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "18531c88",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "This special case works via a score: \n",
    "- each data involves a set event on a synth (sent via OSC)\n",
    "- but alternatively mapping could also be managed by buffers\n",
    "- then each buffer directly modulates the amplitude of an oscillator\n",
    "- For that we can already show a special Sonecule:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "44014a42",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Timbral-Sonification (as own sonecule via buffers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9081624",
   "metadata": {},
   "outputs": [],
   "source": [
    "timbralson = sonecules.buffersyn.TimbralSon(eeg_data[14*256:16*256], sr=256)\n",
    "\n",
    "context.clear()\n",
    "timbralson.schedule(at=0.5, params={\"amp\": 0.05, \"f0\": 120, \"rate\": 0.5})\n",
    "playback.start(rate=1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ceb9d96e",
   "metadata": {},
   "source": [
    "- this scales better with high-frequency data (e.g. >1000 changes/second)\n",
    "- a score-based approach would result in issues such as\n",
    "  - Python CPU bottleneck\n",
    "  - non-accurate (due to control rate being lower than audio rate)\n",
    "- but this depends on the backend "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a6db5c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "sonecules.stop() "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f58b37da",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Classical Parameter Mapping Sonification"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ea87fe1b",
   "metadata": {},
   "source": [
    "There are several ways of doing classical parameter mapping (both discrete and continuous)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e388c5b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sonecules.scoresyn import StandardContinuousPMSon, StandardDiscretePMSon\n",
    "from sc3nb import midicps, linlin"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "842194d2",
   "metadata": {},
   "source": [
    "Let's work with the penguins data set (measures of penguins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9adfcc7",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "penguins_df.head(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "998f4950",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "# penguins_df[['body_mass_g', 'flipper_length_mm']).plot()\n",
    "sns.pairplot(data=penguins_df, hue=\"species\", x_vars='body_mass_g', y_vars='flipper_length_mm');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4525b446",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "context.clear()\n",
    "\n",
    "scpmson = StandardContinuousPMSon(\"s2\", \n",
    "    {\"freq\": {\"bounds\": (midicps(30), midicps(90))},  # bounds checking in mesonic is too strict currently\n",
    "     \"amp\": {\"default\": 0.1}}\n",
    ")\n",
    "\n",
    "dlinlin = lambda value, dmin, dmax, y1, y2: linlin(value, x1=dmin, x2=dmax, y1=y1, y2=y2)\n",
    "\n",
    "test_mapping = {\n",
    "    \"onset\": (\"body_mass_g\", dlinlin, {\"y1\": 0, \"y2\": 3}),\n",
    "    \"freq\" : (\"flipper_length_mm\", dlinlin, {\"y1\": midicps(40), \"y2\": midicps(80)})\n",
    "}\n",
    "\n",
    "scpmson.schedule(df=penguins_df, mapping=test_mapping, at=0, stop_after=0.2)\n",
    "\n",
    "playback.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "271eeb1e",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "outputs": [],
   "source": [
    "# Error message when bounds are not respected by the mapping are currently quite hard to understand\n",
    "# should fix this in mesonic "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f764c502",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "context.clear() \n",
    "\n",
    "sdpmson = StandardDiscretePMSon(\"s1\", \n",
    "    {\"freq\": {\"bounds\": (midicps(49.9), midicps(70.1))},  # bounds checking in mesonic is too strict currently\n",
    "     \"amp\": {\"default\": 0.1},\n",
    "     #\"dur\": {\"default\": 0.2}\n",
    "    }\n",
    ")\n",
    "\n",
    "test_mapping = {\n",
    "    \"onset\": (\"body_mass_g\", dlinlin, {\"y1\": 0, \"y2\": 3}),\n",
    "    \"dur\": (\"body_mass_g\", dlinlin, {\"y1\": 0.05, \"y2\": 0.1}),\n",
    "    \"freq\" : (\"flipper_length_mm\", dlinlin, {\"y1\": midicps(50), \"y2\": midicps(70)})\n",
    "}\n",
    "\n",
    "sdpmson.schedule(df=penguins_df, mapping=test_mapping, at=0, stop_after=0.2)\n",
    "playback.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e82af2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "context.timeline.plot()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3ed7b07a",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Continuous Parameter Mapping with specifying a callback function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53b30651",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sonecules.scoresyn import CPMSonCB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d19c4298",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.figure(); Asig(bld_df.iloc[:24*7, 8:].values, sr=24).plot(offset=1); plt.grid(); plt.title(\"Building Dataset\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4570dce2",
   "metadata": {},
   "outputs": [],
   "source": [
    "scb = CPMSonCB(bld_df.iloc[:7*24, 6:])  # one week\n",
    "# scb = CPMSonCB(bld_df.iloc[:4000, 7:])  # whole dataset\n",
    "\n",
    "mapcol = scb.mapcol\n",
    "\n",
    "def callback_fn(r, cmi, cma, pp):\n",
    "    pp['freq']      = scn.midicps(mapcol(r, 'temperature', cmi, cma, 48, 72))\n",
    "    pp['amp']       = scn.dbamp(mapcol(r, 'humidity', cmi, cma, -30, -10)) \n",
    "    pp['pan']       = mapcol(r, 'hc_wb_electrical', cmi, cma, -1, 1)\n",
    "    pp['numharm']   = mapcol(r, 'solar_radiation', cmi, cma, 1, 6)\n",
    "    pp['vibfreq']   = scn.linlin(r['hc_wb_hot_water'], -0.5, 0.5, 3, 8)\n",
    "    pp['vibintrel'] = 0\n",
    "    return pp\n",
    "\n",
    "context.clear()\n",
    "scb.schedule(at=0, duration=4, callback_fn=callback_fn)\n",
    "playback.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3be8799",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "scb.create_callback_template(auto_assign=True);"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "52d448f0",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Model-Based Sonification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06e71892",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sonecules.triggersyn import DataSonogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47cd1d19",
   "metadata": {},
   "outputs": [],
   "source": [
    "sonecules.reset()\n",
    "sonecules.gcc().enable_realtime()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87492325",
   "metadata": {},
   "outputs": [],
   "source": [
    "s1.start(freq=np.random.random()*500, dur=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3031e15",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4fe675d",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "dsg = DataSonogram(penguins_df, x=\"flipper_length_mm\", y=\"bill_length_mm\", label=\"species\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "24f9184c",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Goals"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "251c4929",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## availability and distribution\n",
    "\n",
    "* sonifications as reusable units\n",
    "* growing (crowd sourced) collection"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0eb3afe3",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## reproducibility\n",
    "\n",
    "* benchmarking\n",
    "* enchancing scientific standards and development"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "db91578b",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## sonification to the masses\n",
    "\n",
    "* spreading sonifications as quickly usable tools\n",
    "* reaching and enabling people without sonification expertise\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "650b4bac",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "cc506777",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# mesonic concepts\n",
    "\n",
    "<center>\n",
    "<img src=\"./figures/mesonic-concepts.jpg\"/>\n",
    "</center>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e7c5f6be",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# matplotlib\n",
    "\n",
    "<center>\n",
    "<img src=\"./figures/anatomy-of-figure.jpg\"/>\n",
    "</center>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e3192edf",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# mesonic - audio objects\n",
    "\n",
    "<center>\n",
    "<img src=\"./figures/mesonic-synth.jpg\"/>\n",
    "</center>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3531b0c5",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* practical use: discrete vs continuous Parameter Mapping Sonification"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9e2e9838",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* inspired by Enge et al. 2021 - **0D / 1D auditory mark**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "057cfbcd",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# mesonic - audio objects\n",
    "\n",
    "<center>\n",
    "<img src=\"./figures/mesonic-buffer-record.jpg\"/>\n",
    "</center>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d99d0ccc",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "- the Context can be regarded as counterpart of the Figure from matplotlib and as the central interface\n",
    "    - it controls the backend which is clearly separated and designed to be exchangeable\n",
    "\n",
    "- The Backend provides different Managers to create the Audio Objects\n",
    "- and is also responsible for creating the Audio Object EventHandlers that will create sound in the backend \n",
    "\n",
    "\n",
    "- The Audio Objects  are the available building blocks for the sonification which are inspired by common concepts from sound synthesis software\n",
    "- The different objects offer actions like f.e. starting a Synth with a certain frequency\n",
    "  These however do not directly generate sounds but rather create Events \n",
    "\n",
    "\n",
    "- The events are then passed to the Context which provides the sonification time for the event.\n",
    "  The Event then will be inserted into the timeline as a bundles \n",
    "\n",
    "- The Timeline then forms a data structure that contains all the actions from the sonification\n",
    "\n",
    "- To actually listen to the sonification the events in the timeline can be rendered offline or by the playback\n",
    "\n",
    "- The playback offers an interactive control over the sonification and allows f.e. filtering by data source via the BundleProcessor before passing the events to the Audio Object EventHandler in the Backend \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "619cca67",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow"
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
