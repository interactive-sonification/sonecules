{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sonecule: ContinuousPMS â€“ Continuous Parameter-Mapping Sonification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook introduces and demonstrates usage of the ContinousPMS sonecule.\n",
    "* The sonecule uses a synth that creates a continuous sound stream \n",
    "* for that a synth is used that offers several parameters that can be modulated\n",
    "* Specifically the parameters are:\n",
    "  * amplitude\n",
    "  * frequency\n",
    "  * number of harmonics\n",
    "  * spatial panning\n",
    "* Most likely, a custom synth will be created and passed on for individual sonifications, replacing the default.\n",
    "* The mapping specifies how data channels shall control the individual parameters\n",
    "* "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# headers and imports for the demo\n",
    "import sonecules as sn\n",
    "import sc3nb as scn\n",
    "from pya import Asig\n",
    "import pyamapping as pam\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "\n",
    "# setup for matplotlib \n",
    "plt.rcParams[\"figure.figsize\"] = (8,3)\n",
    "%matplotlib widget\n",
    "\n",
    "def a2d(**kwargs):\n",
    "    return kwargs \n",
    "\n",
    "# start sonecules (with default backend sc3nb, aka sc3)\n",
    "sn.startup()\n",
    "ctx = sn.gcc()  # get the context as ctx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load data sets used for the demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ../examples/prepare-data.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # select test data for sonecule, here EEG data from an epilepsy\n",
    "# dasig = Asig(eeg_data, sr=250)\n",
    "# plt.figure(figsize=(12,2)); \n",
    "# plt.subplot(121); dasig.plot(offset=1)\n",
    "\n",
    "# data = dasig[{7:11}, [0,1,2,5,9,12]][::5]\n",
    "# plt.subplot(122); data.plot(offset=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = bld_df\n",
    "df['nr'] = df.index\n",
    "df.iloc[:,10:-1].plot(lw=0.5, subplots=True, figsize=(9,6)); plt.tight_layout()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Usage Demo for the ContinuousPMS Sonecule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mesonic.synth import Synth\n",
    "from sonecules.scoresyn import ContinuousPMS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code cell shows everything needed \n",
    "- to create the sonecule with data, \n",
    "- to clear the auditory canvas (aka timeline)\n",
    "- to start the playback at a given rate\n",
    "- to plot the timeline."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usually we want to use a specific synths which we would define using the backend.\n",
    "- In this case the default backend is sc3nb, so we can create it using scn.SynthDef\n",
    "- Later sonecules will offer a well curated library of pre-packaged synths, so that it is rarely necessary to craft your own.\n",
    "- The default synth (if none is provided is \"cpmssyn\", a 'continuous synth for PMSon'). \n",
    "- It is a pitched tone with added vibrato \n",
    "- It offers the continuous controls:\n",
    "\n",
    "| parameter   | range  | meaning                                         |\n",
    "| ----------- | ------ | ----------------------------------------------- |\n",
    "| freq:       | [20..] | frequency                                       |\n",
    "| amp         | [0,1]  | amplitude                                       |\n",
    "| brightness: | [0,10] | brightness, the higher the more sharp the sound |\n",
    "| pan         | [-1,1] | spatial panning from left to right              |\n",
    "| plfreq      | [0..]  | multiplied pulse frequency                      |\n",
    "| plwid       | [0,1]  | duty cycle of the pulse                         |\n",
    "| plint       | [0,1]  | intensity of the pulse modulation               |\n",
    "\n",
    "As currently no default synths are implemented we have to do the work ourselves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scn.SynthDef(\"syc0\", \n",
    "\"\"\"{ | out=0, freq=400, amp=0.1, plfreq=0, plwid=0.5, plint=0, brightness=0, pan=0, lg=0 | \n",
    "    var f = freq.lag(lg);\n",
    "    var pulse = LFPulse.ar(plfreq, width: plwid, mul: plint, add: 1-plint);\n",
    "    var tone = HPF.ar(Formant.ar(f, f, bwfreq: f * (brightness + 1)), 40);\n",
    "    Out.ar(out, Pan2.ar(tone*pulse, pan.lag(lg), level: amp.lag(lg)));\n",
    "}\"\"\").add()\n",
    "\n",
    "scn.SynthDef(\"sycvib\", \n",
    "\"\"\"{ | out=0, freq=400, amp=0.1, vibfreq=0, vibintrel=0, brightness=0, pan=0, lg=0 | \n",
    "    var vib = SinOsc.ar(vibfreq, mul: vibintrel*freq, add: freq.lag(lg));\n",
    "    var sig = HPF.ar(Formant.ar(vib, vib, bwfreq: vib*brightness+1, mul: amp.lag(lg)), 40);\n",
    "    Out.ar(out, Pan2.ar(sig, pan.lag(lg)));\n",
    "}\"\"\").add()\n",
    "\n",
    "scn.SynthDef(\"sycnoise\", \n",
    "\"\"\"{ | out=0, freq=400, amp=0.1, rq=0.1, pan=0, lg=0 | \n",
    "    var sig = BPF.ar(WhiteNoise.ar(amp), freq.lag(lg), rq.lag(lg));\n",
    "    Out.ar(out, Pan2.ar(sig, pan.lag(lg)));\n",
    "}\"\"\").add()\n",
    "\n",
    "scn.SynthDef(\"syctick\", \n",
    "\"\"\"{ | out=0, freq=400, cf=4000, amp=0.1, pan=0, lg=0 | \n",
    "    var sig = LPF.ar(Impulse.ar(freq.lag(lg)), cf.lag(lg));\n",
    "    Out.ar(out, Pan2.ar(sig, pan.lag(lg), amp));\n",
    "}\"\"\").add()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # demo for the syctick\n",
    "# sx = scn.Synth(\"syctick\", a2d(freq=80, amp=0.05, cf=2000, pan=0))\n",
    "# time.sleep(1); sx.set(a2d(lg=0.5, freq=15, cf=3000, amp=0.2, pan=-1))\n",
    "# time.sleep(1); sx.set(a2d(lg=0.5, freq=5, cf=7000, amp=0.1, pan=1))\n",
    "# time.sleep(1); sx.set(a2d(lg=0.5, freq=25, cf=2000, amp=0.1, pan=1)) \n",
    "# time.sleep(1); sx.set(a2d(lg=0.5, freq=45, cf=2000, amp=0.3, pan=1)) \n",
    "# time.sleep(1); sx.free()\n",
    "# # demo for the sycnoise\n",
    "# sx = scn.Synth(\"sycnoise\", a2d(freq=800, amp=0.05, rq=0.1, pan=0))\n",
    "# time.sleep(1); sx.set(a2d(lg=0.5, freq=500,  rq=0.1, amp=0.2, pan=-1))\n",
    "# time.sleep(1); sx.set(a2d(lg=0.5, freq=5000, rq=0.5, amp=0.1, pan=1))\n",
    "# time.sleep(1); sx.set(a2d(lg=0.5, freq=2000, rq=1.2, amp=0.1, pan=1)) \n",
    "# time.sleep(1); sx.set(a2d(lg=0.5, freq=400,  rq=0.1, amp=0.3, pan=1)) \n",
    "# time.sleep(1); sx.free()\n",
    "# use this code to explore the synths as you see fit\n",
    "# def a2d(**kwargs):\n",
    "#     return kwargs \n",
    "# sx = scn.Synth(\"sycpms\", a2d(freq=200, amp=0.05, plfreq=5, plwid=0.1, brightness=4, pan=0))\n",
    "# sx.pfreq = 20\n",
    "# sx.plwid = 0.7\n",
    "# sx.set('plint', 0.5)\n",
    "# sx.free()\n",
    "# scn.SC.default.server.free_all()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next cell shows all steps in specifying the mapping in one go"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a sonecule, initialized with the synth to be used\n",
    "# second argument can provide defaults and bounds for parameters\n",
    "sncpms = ContinuousPMS(\"syc0\", { \n",
    "    \"freq\": {\"bounds\": (100, 5000)},\n",
    "    \"amp\": {\"default\": 0.1},\n",
    "    \"brightness\": {\"default\": 0},\n",
    "    \"lg\": {\"default\": 0.1}\n",
    "    })\n",
    "\n",
    "# the mapping is just a dictionary where keys are the parameters,\n",
    "# and values are tuples of \n",
    "# - data column, \n",
    "# - mapping type, and  \n",
    "# - arguments of the mapping function as dictionary, e.g.\n",
    "test_mapping = {\n",
    "    \"onset\": (\"nr\", \"lin\", {\"y1\": 0, \"y2\": 4}),\n",
    "    \"freq\" : (\"humidity\", \"exp\", {\"y1\": pam.midi_to_cps(50), \"y2\": pam.midi_to_cps(70)}),\n",
    "    \"brightness\" : (\"temperature\", \"lin\", {\"y1\": 0, \"y2\": 10}),\n",
    "    \"pan\" : (\"solar_radiation\", \"lin\", {\"y1\": -1, \"y2\": 1}),\n",
    "}\n",
    "\n",
    "# clear the timeline \n",
    "ctx.timeline.reset() \n",
    "\n",
    "# and render the sonification into the timeline\n",
    "sncpms.schedule(df=df.iloc[0:10*24], mapping=test_mapping)\n",
    "\n",
    "# finally start the realtime playback at a given rate\n",
    "sncpms.start(rate=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usually this can be done in a more condensed way, by\n",
    "- omitting the defaults and bounds (later synths will come with good such values anyway)\n",
    "- using shortcuts such as providing [min, max] instead of {\"y1\": min, \"y2\": max}\n",
    "- setting constant values by value\n",
    "- defining the mapping in the call\n",
    "- starting the sonification by daisy chaining\n",
    "as shown here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a sonecule, initialized with your data selection\n",
    "sncpms = ContinuousPMS(\"syc0\")\n",
    "ctx.timeline.reset() \n",
    "sncpms.schedule(df=df.iloc[4*24:14*24], mapping={\n",
    "    \"onset\":        (\"nr\", \"lin\", (0, 10)),\n",
    "    \"freq\" :        (\"humidity\", \"exp\", (100, 400)),\n",
    "    \"brightness\" :  (\"temperature\", \"lin\", (2, 8)),\n",
    "    \"pan\" :         (\"solar_radiation\", \"lin\", (-1, 1)),\n",
    "    \"amp\" :         (\"wind_speed\", \"exp\", (0.02, 1)),\n",
    "    \"lg\" : 0.05,\n",
    "    }).start()\n",
    "\n",
    "# as bonus: lets plot the used data\n",
    "df.iloc[4*24:14*24].loc[:, ['humidity', 'temperature', 'solar_radiation', 'wind_speed']].plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the events remain in the timeline. \n",
    "Setting the "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ctx.timeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setting the time actively to 0 will cue the playback to that onset and result in\n",
    "a sonification to be replayed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ctx.realtime_playback.time = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to free the timeline use\n",
    "ctx.clear()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to stop all sound playing via the backend use \n",
    "ctx.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# note that the playback's latency is >0 - it can also be set\n",
    "# but see mesonic for details and help\n",
    "ctx.realtime_playback.processor.latency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for own mapping experiments, its useful to see all columns\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# as long as we reuse the synth, no need to create the object, but just use with different mappings\n",
    "ctx.timeline.reset() \n",
    "sncpms.schedule(df.iloc[10*24:60*24], mapping={\n",
    "    \"onset\":        (\"nr\",                  \"lin\", [0, 10]),\n",
    "    \"freq\" :        (\"solar_radiation\",     \"exp\", [pam.midi_to_cps(40), pam.midi_to_cps(52)]),\n",
    "    \"brightness\" :  (\"temperature\",         \"lin\", [0, 10]),\n",
    "    \"pan\" :         (\"humidity\",            \"lin\", [-1, 1]),\n",
    "    \"amp\" : 0.2\n",
    "}\n",
    ").start(rate=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyrbid Continuous Parameter Mappings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now explore a more interesting mapping:\n",
    "- together with the above mapping of s\n",
    "- to play impulses for the electricity\n",
    "- wind sounds for the wind speed\n",
    "- and map the water use on pulse choppings of the stream"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ctx.managers['synths']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a sonecule, initialized with your data selection\n",
    "dfsel = df.iloc[4*24:14*24]\n",
    "ctx.timeline.reset() \n",
    "onset_mapping_spec = (\"nr\", \"lin\", (0, 10))\n",
    "\n",
    "s1 = ContinuousPMS(\"syc0\").schedule(dfsel, {\n",
    "    \"onset\":        onset_mapping_spec,\n",
    "    \"freq\" :        (\"temperature\", \"exp\", (100, 400)),\n",
    "    \"brightness\" :  (\"humidity\", \"lin\", (2, 8)),\n",
    "    \"pan\" :         0,\n",
    "    \"amp\" :         (\"solar_radiation\", \"exp\", (0.05, 0.5)),\n",
    "    \"lg\" : 0.05,\n",
    "    })\n",
    "\n",
    "s2 = ContinuousPMS(\"sycnoise\").schedule(dfsel, {\n",
    "    \"onset\":        onset_mapping_spec,\n",
    "    \"freq\" :        (\"wind_speed\", \"exp\", (100, 2000)),\n",
    "    \"pan\" :         0.5,\n",
    "    \"rq\" :          0.4,\n",
    "    \"amp\" :         (\"wind_speed\", \"exp\", (0.2, 0.8)),\n",
    "    \"lg\" : 0.05,\n",
    "    })\n",
    "\n",
    "s3 = ContinuousPMS(\"syctick\").schedule(dfsel, {\n",
    "    \"onset\":    onset_mapping_spec,\n",
    "    \"freq\" :    (\"hc_wb_electrical\", \"exp\", (10, 80)),\n",
    "    \"pan\" : -0.5, \"cf\": 8000, \"amp\":  1, \"lg\": 0.05,\n",
    "    })\n",
    "\n",
    "# as bonus: lets plot the used data\n",
    "dfsel.iloc[:,10:-2].plot(subplots=True, figsize=(10,6));\n",
    "\n",
    "ctx.realtime_playback.start()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the a2d, this could also be written a bit more like code, as"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a sonecule, initialized with your data selection\n",
    "dfsel = df.iloc[4*24:14*24]\n",
    "ctx.timeline.reset() \n",
    "\n",
    "onset_mapping_spec = (\"nr\", \"lin\", (0, 10))\n",
    "\n",
    "s1 = ContinuousPMS(\"syc0\").schedule(dfsel, a2d(\n",
    "    onset = onset_mapping_spec,\n",
    "    freq = (\"temperature\", \"exp\", (100, 400)),\n",
    "    brightness = (\"humidity\", \"lin\", (2, 8)),\n",
    "    amp = (\"solar_radiation\", \"exp\", (0.05, 0.5)),\n",
    "    pan = 0, lg = 0.05,\n",
    "))\n",
    "\n",
    "s2 = ContinuousPMS(\"sycnoise\").schedule(dfsel, a2d(\n",
    "    onset = onset_mapping_spec,\n",
    "    freq = (\"wind_speed\", \"exp\", (100, 2000)),\n",
    "    amp = (\"wind_speed\", \"exp\", (0.2, 0.8)),\n",
    "    pan = 0.5, rq = 0.4, lg = 0.05,\n",
    "))\n",
    "\n",
    "s3 = ContinuousPMS(\"syctick\").schedule(dfsel, a2d(\n",
    "    onset = onset_mapping_spec,\n",
    "    freq = (\"hc_wb_electrical\", \"exp\", (10, 80)),\n",
    "    pan = -0.5, cf = 8000, amp = 1, lg = 0.05,\n",
    "))\n",
    "\n",
    "# as bonus: lets plot the used data\n",
    "# dfsel.iloc[:,10:-2].plot(subplots=True, figsize=(10,6))\n",
    "\n",
    "ctx.realtime_playback.start()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code Template"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code snippets are intended for copy & paste to your notebooks, to facilitate getting your data sonified\n",
    "using this sonecule.\n",
    "* It is assumed that your data is stored in an Asig dasig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load your multi-channel data into an Asig, e.g. \n",
    "data = np.random.random((1000, 4))-0.5 # 100 rows with 8 channels, here same fake data\n",
    "data = np.cumsum(data,axis=0)\n",
    "df = pd.DataFrame(data, columns=[\"c1\", \"c2\", \"c3\", \"c4\"])\n",
    "df['nr'] = df.index\n",
    "df.plot(subplots=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scn.SynthDef(\"syc0\", \n",
    "\"\"\"{ | out=0, freq=400, amp=0.1, plfreq=0, plwid=0.5, plint=0, brightness=0, pan=0, lg=0 | \n",
    "    var f = freq.lag(lg);\n",
    "    var pulse = LFPulse.ar(plfreq, width: plwid, mul: plint, add: 1-plint);\n",
    "    var tone = HPF.ar(Formant.ar(f, f, bwfreq: f * (brightness + 1)), 40);\n",
    "    Out.ar(out, Pan2.ar(tone*pulse, pan.lag(lg), level: amp.lag(lg)));\n",
    "}\"\"\").add()\n",
    "\n",
    "# load your data / select your data\n",
    "mydf = df\n",
    "\n",
    "# sonecule for your synth with defaults and bounds\n",
    "sncpms = ContinuousPMS(\"syc0\", { \n",
    "    \"freq\": {\"bounds\": (100, 5000)},\n",
    "    \"amp\": {\"default\": 0.5},\n",
    "    \"brightness\": {\"default\": 0},\n",
    "    \"lg\": {\"default\": 0.01}\n",
    "    })\n",
    "\n",
    "# mapping dictionary \n",
    "test_mapping = {\n",
    "    \"onset\":       (\"nr\", \"lin\", [0, 8]),\n",
    "    \"freq\" :       (\"c1\", \"exp\", {\"y1\": pam.midi_to_cps(50), \"y2\": pam.midi_to_cps(70)}),\n",
    "    \"brightness\" : (\"c2\", \"lin\", {\"y1\": 0, \"y2\": 10}),\n",
    "    \"plfreq\" :     (\"c3\", \"lin\", {\"y1\": 5, \"y2\": 25}),\n",
    "    \"plint\" : 1, \"plwid\": 0.5,\n",
    "}\n",
    "\n",
    "# clear the timeline \n",
    "ctx.timeline.reset() \n",
    "\n",
    "# and render the sonification into the timeline\n",
    "sncpms.schedule(df=mydf, mapping=test_mapping)\n",
    "\n",
    "# finally start the realtime playback at a given rate\n",
    "sncpms.start(rate=1)\n",
    "\n",
    "# if needed: plot the timeline using \n",
    "ctx.timeline.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 2
}
