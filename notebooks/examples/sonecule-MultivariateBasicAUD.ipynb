{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sonecule: MultivariateBasicAUD â€“ A basic playbuf driven Audification of n-dimensional data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook introduces and demonstrates usage of the MultivariateBasicAUD sonecule.\n",
    "- The sonecule enables a simple Audification of a data frame with n channels.\n",
    "- It can be initialized with \n",
    "  - a pya Asig (i.e. audio signal using pya)\n",
    "    - `MultivariateBasicAUD(asig, sr=None, channel=0)`\n",
    "  - a pandas DataFrame or Series\n",
    "    - `MultivariateBasicAUD.from_df(df, sr=None, time_column=None)`\n",
    "  - a numpy ndarray\n",
    "    - `.from_np(data, sr, time_column=None)`\n",
    "- Preprocessing such as time stretching, slicing, filtering is offered by specialized functions, either in pya (iirfilter, stretch) or libraries such as scipy.signal - correspondingly processed signals can be passed into Audification modules for audition and interaction.\n",
    "- The current MultivariateBasicAUD uses SuperCollider3, controlled via sc3nb, as Backend and therein uses a PlayBuf UGen for audification, which allows one-shot, looped, or repeatedly triggered playback of a data buffer.\n",
    "- It is a hybrid sonecule, i.e. it wraps n BasicAUD sonecules and orchestrates their controls.\n",
    "- The synth is mutable, i.e. its parameters can be controlled interactively (code or GUI)\n",
    "  - should enable pause/resume\n",
    "  - with rate control (note: not band-limited!): a number, shared for all channels\n",
    "  - with amp control: a number or array/list (then amplitude for individual channels)\n",
    "  - with pan control: a number or array/list (then panning for individual channels)\n",
    "  - with onset (i.e. at in schedule)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's get started. First some imports and settings and startup of sonecules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# headers and imports for the demo\n",
    "import sonecules as sn\n",
    "import sc3nb as scn\n",
    "from pya import Asig\n",
    "import pyamapping as pam\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "\n",
    "# setup for matplotlib \n",
    "plt.rcParams[\"figure.figsize\"] = (8,3)\n",
    "%matplotlib widget\n",
    "\n",
    "# start sonecules (with default backend sc3nb, aka sc3)\n",
    "sn.startup()\n",
    "ctx = sn.gcc()  # get the context as ctx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load data sets used for the demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ../examples/prepare-data.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ctx.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = dataframes['eeg'].loc[:, [1,4,7,10]]\n",
    "df.plot(subplots=True);\n",
    "# df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Usage Demo for the MultivariateBasicAUD Sonecule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mesonic.synth import Synth\n",
    "from sonecules.buffersyn import MultivariateBasicAUD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code cell shows everything needed \n",
    "- to create the sonecule with data, \n",
    "- to clear the auditory canvas (aka timeline)\n",
    "- to start the playback at a given rate\n",
    "- to plot the timeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the sonecule from data (e.g. channels 1 and 7 of the EEG data set )\n",
    "aud = MultivariateBasicAUD.from_df(df, sr=256, columns=[1,7])\n",
    "# clear the timeline \n",
    "ctx.timeline.reset()\n",
    "\n",
    "# schedule the event (which is just one: to start the synth)\n",
    "aud.schedule(at=0, rate=20, pan=[-1,1], loop=0, amp=[0.5,0.5]).start()\n",
    "\n",
    "# plot the data (just for fun)\n",
    "df.plot(subplots=True);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the MultivariateBasicAUD instance is available, you can replay it as needed with different parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ctx.timeline.reset()\n",
    "# BUG:  scsynth reports scsynth /fail /s_new when called with at = 0.0\n",
    "aud.schedule(at=0.1, rate=50, pan=0, loop=0, startpos=4000, amp=0.8).start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the sonecule from data using all channels by leaving columns unassigned \n",
    "aud = MultivariateBasicAUD.from_df(df, sr=256)\n",
    "# clear the timeline \n",
    "ctx.timeline.reset()\n",
    "\n",
    "# schedule the event (which is just one: to start the synth)\n",
    "# pan has a special keyword \"spread\", to distribute all channels from full left to full right\n",
    "aud.schedule(at=0.1, rate=20, pan=\"spread\", loop=1, amp=0.3).start()\n",
    "\n",
    "# plot the data (just for fun)\n",
    "df.plot(subplots=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aud.set(amp=[1,0,0,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aud.set(amp=[0,0,0,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aud.set(amp=[0.5,0.3,0.3,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aud.set(rate=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aud.set(pan=[-1,1,1,-1], rate=40, trfreq=3, startpos=3000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aud.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MultivariateBasicAUD offers the same features as BasicAUD, see the BasicAUD example notebook\n",
    "- Please check there how to use startpos, trfreq to skim interactively through data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can easily control the Audification with some sliders\n",
    "* move the startpos slider to skim through the audification\n",
    "* control rate and trigger rate independently\n",
    "* the GUI shows howto create faders for the four channels to listen to channels in the foreground with others in the background"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipywidgets import interactive\n",
    "aud.schedule(at=0, rate=100, pan=[-1,-0.3,0.3,1], loop=1, startpos=0, amp=0.8, trfreq=1).start() \n",
    "def aud_gui(startpos=0, trfreq=1, rate=50, amp1=0.1, amp2=0.1, amp3=0.1, amp4=0.1):\n",
    "    aud.set(startpos=startpos, trfreq=trfreq, rate=rate, amp=[amp1, amp2, amp3, amp4])\n",
    "interactive(aud_gui, startpos=(0, 12000, 100), trfreq=(1, 50, 1), rate=(1, 200, 1),\n",
    "    amp1=(0,1,0.01), amp2=(0,1,0.01), amp3=(0,1,0.01), amp4=(0,1,0.01)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# and stop when done\n",
    "aud.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Signal Conditioning**\n",
    "\n",
    "* Basic Audification doesn't offer filtering or distortion, or multi-channel capabilities.\n",
    "* These, however, are made available in more specialized Sonecules of the AUD family.\n",
    "* However, some signal conditionings are better applied before audition anyway!\n",
    "* Modifications such as applying a time scale modification (aka time stretching, i.e. rescaling the time without modifying the spectrum), is for instance well done in pya using Asig.stretch(factor) as shown here for a selected channel and time interval and stretch factor in a one-liner\n",
    "\n",
    "      aud1 = BasicAUD(my_asig[{1.5:5.2},['channelname']].stretch(3.5))\n",
    "\n",
    "* so while Sonecules probably don't do it all, combinations with pandas and pya functions enable swift, and flexible implementations of what is needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytsmod as tsm\n",
    "a1 = Asig(df.loc[:, 7].values, sr=256)\n",
    "stretch_factor = 5.5\n",
    "ar = Asig(tsm.wsola(a1.sig.T, s=stretch_factor).T, sr=a1.sr)\n",
    "ar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code Template"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code snippets are intended for copy & paste to your notebooks, to facilitate getting your data sonified\n",
    "using this sonecule.\n",
    "* It is assumed that your data is stored in an Asig dasig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create or load your data, e.g.\n",
    "\n",
    "df = dataframes['ecg']\n",
    "\n",
    "data = df.values\n",
    "columns = [str(i) for i in list(df.columns)]\n",
    "\n",
    "# or load data\n",
    "# data = pd.read_csv(\"your_csv_file.csv\", delimiter=\",\")\n",
    "# data = pd.read_excel(\"your_excel_file.xlsc\") # see pandas documenation\n",
    "\n",
    "# put it into an Asig\n",
    "a1 = Asig(data, sr=200, cn=columns)\n",
    "plt.figure(); a1.plot(offset=1)\n",
    "a1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load your data / select your data\n",
    "myasig = a1\n",
    "\n",
    "# sonecule for your synth with defaults and bounds\n",
    "aud = MultivariateBasicAUD(myasig)\n",
    "\n",
    "# clear the timeline \n",
    "ctx.timeline.reset() \n",
    "\n",
    "# finally start the realtime playback at a given rate\n",
    "aud.schedule(at=0.5, rate=5, loop=1, amp=0.2, pan=\"spread\").start()\n",
    "\n",
    "# if needed: plot the timeline using \n",
    "ctx.timeline.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# play the 4 outer channels louder\n",
    "aud.set(amp=[1,-0.3,0,0,-0.3,1], pan=[-1,-1,0,0,1,1], rate=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# play the two center channels and mute the outer\n",
    "aud.set(amp=[0,0,0.8,0.8,0,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aud.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 2
}
