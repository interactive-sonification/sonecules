{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sonecule: TimbralPMS â€“ Timbral Parameter Mapping Sonification of multivariate data series"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook introduces and demonstrates usage of the `TimbralPMS` sonecule.\n",
    "- The sonecule enables Timbral Sonification, i.e., the sonification of a multivariate data set where each channel controls the amplitude of a partial of a pitched sounds consisting of multiple harmonics.\n",
    "- It can be initialized with \n",
    "  - a pya Asig (i.e. audio signal using pya)\n",
    "    - `TimbralPMS(asig, sr=None, channels=None)`\n",
    "  - a pandas DataFrame or Series\n",
    "    - `TimbralPMS.from_df(df, sr=44100, time_column=None, columns=None)`\n",
    "  - a numpy ndarray\n",
    "    - `TimbralPMS.from_np(data, sr=44100, time_column=None, columns=None)`\n",
    "- Preprocessing such as time stretching, slicing, filtering is offered by specialized functions, either in pya (iirfilter, stretch) or libraries such as scipy.signal - correspondingly processed signals can be passed into TimbralPMS Sonecules for audition and interaction.\n",
    "- The current TimbralPMS uses the SuperCollider3 via the sc3nb backend of mesonic, and uses a single sc3 `PlayBuf` UGen operating on a $d$-channel buffer. Different from audification, here the values read from the buffer control the amplitude of a battery of (overtone) sine waves.\n",
    "- The synth is mutable, i.e., its parameters can be controlled interactively (via code or GUI)\n",
    "  - should enable pause/resume\n",
    "  - control parameters are\n",
    "    - freq: the fundamental frequency of the sound\n",
    "    - rate: how fast the the Buffer is read (==1 for at sampling rate sr)\n",
    "    - amp: the amplitude \n",
    "    - pan: the stereo position at which the sound appears in the mix\n",
    "  - with onset (in schedule)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's get started. First some imports and settings and startup of sonecules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# headers and imports for the demo\n",
    "import sonecules as sn\n",
    "from pya import Asig\n",
    "import pyamapping as pam\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# setup for matplotlib \n",
    "plt.rcParams[\"figure.figsize\"] = (8,3)\n",
    "%matplotlib widget\n",
    "\n",
    "# start sonecules (with default backend sc3nb, aka sc3)\n",
    "sn.startup()\n",
    "ctx = sn.gcc()  # get the context as ctx\n",
    "ctx.enable_realtime();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load data sets used for the demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ../data/prepare-data.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's use EEG data to demonstrate `TimbralPMS`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = dataframes['eeg'].loc[:, :]\n",
    "df.plot(subplots=True, lw=0.5);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Usage Demo for the TimbralPMS Sonecule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sonecules.bufferson import TimbralPMS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code cell shows everything needed \n",
    "- to create the sonecule with data, \n",
    "- to reset the auditory canvas (the timeline)\n",
    "- to start the playback at a given rate\n",
    "- to plot the timeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the sonecule from data (e.g. channel 7 of the EEG data set )\n",
    "tson = TimbralPMS.from_df(df, sr=256) \n",
    "# plot the data (just for fun)\n",
    "plt.figure(); tson.dasig.plot(offset=1, lw=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (re)schedule the event (which is just one: to start the synth)\n",
    "tson.reschedule(at=0, rate=3, freq=60, pan=0, amp=0.1, loop=0).start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's listen to the onset of the epilepsy in realime\n",
    "ctx.reset()\n",
    "tson = TimbralPMS(Asig(df.values, sr=256)[{6.2:10.4},::2]) # use even channels\n",
    "tson.schedule(at=0, rate=1, freq=50, startpos=0, trfreq=0, pan=0, amp=0.1, loop=1).start()\n",
    "plt.figure(); tson.dasig.plot(offset=1, lw=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can set startPos (Attention: in samples, not duration!) and trfreq to make a selection\n",
    "tson.set(trfreq=0.1, rate=0.5, startpos=256*1.8, amp=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tson.set(freq=40, rate=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# or interact with a GUI\n",
    "from ipywidgets import interactive\n",
    "def xplore(startpos=256):\n",
    "    tson.set(rate=0, startpos=startpos, trfreq=20)\n",
    "interactive(xplore, startpos=(0, 1000, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tson.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next demonstration shows with how few lines of code you can probe the timbre:\n",
    "\n",
    "Simply execute the cell and move the mouse pointer along the x-axis in the plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# or probe the plot interactively \n",
    "tson = TimbralPMS(Asig(df.values, sr=256)[{6.2:10.4},::]) # use even channels\n",
    "ctx.timeline.reset()\n",
    "tson.schedule(at=0, rate=0, freq=50, startpos=0, trfreq=30, pan=0, amp=0.1, loop=1).start()\n",
    "\n",
    "# and now the GUI\n",
    "fig = plt.figure()\n",
    "ax = tson.dasig.plot(offset=1)\n",
    "def on_motion(event):\n",
    "    try: tson.set(startpos=event.xdata * tson.dasig.sr)\n",
    "    except: pass\n",
    "cid = fig.canvas.mpl_connect('motion_notify_event', on_motion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stop the sonification\n",
    "tson.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remember that you can always use stop all playing synth and the playback of the backend ctx by\n",
    "ctx.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code Template"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code snippets are intended for copy & paste to your notebooks, to facilitate getting your data sonified\n",
    "using this sonecule.\n",
    "* It is assumed that your data is stored in an `Asig` dasig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create or load your data\n",
    "a1 = Asig(dataframes['ecg'].values, sr=200)\n",
    "\n",
    "# alternatively (see pandas documenation)\n",
    "# data = pd.read_csv(\"your_csv_file.csv\", delimiter=\",\")\n",
    "# data = pd.read_excel(\"your_excel_file.xlsc\") \n",
    "# and a1 = Asig(data)\n",
    "plt.figure();a1.plot(offset=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reset the timeline\n",
    "# only neccessary here if you are going to run this cell multiple times\n",
    "# because on every execution a TimbralPMS is created and scheduled and this clutters the timeline\n",
    "ctx.timeline.reset() \n",
    "\n",
    "# load your data / select your data\n",
    "myasig = Asig(dataframes['ecg'].values, sr=200)\n",
    "\n",
    "# any preprocessing here: e.g. if we want warped data \n",
    "myasig.sig = np.abs(a1.sig)**0.5\n",
    "\n",
    "# sonecule for your synth with defaults and bounds\n",
    "tson = TimbralPMS(myasig)\n",
    "\n",
    "# finally start the realtime playback at a given rate\n",
    "tson.schedule(at=0, rate=0.5, freq=100).start();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# execute stop in case you don't want the sonification to continue\n",
    "tson.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ctx.close()  # close the mesonic context, exits backend gracefully"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 2
}
