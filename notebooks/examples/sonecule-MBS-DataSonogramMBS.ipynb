{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sonecule: DataSonogramMBS – Data Sonogram Model Based Sonification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook introduces and demonstrates usage of `DataSonogramMBS`, the Data Sonogram Model Based Sonification sonecule.\n",
    "* The sonecule creates a 2D plot showing the first two dimensions of the data frame\n",
    "* A `on_click` interaction is bound to the plot allowing users to excite the sonification model.\n",
    "* On a Mouse click at any position in the plot the nearest neighbor in the 2D scatter is identified\n",
    "* Then a shockwave is triggered to emanate from that location, however, it spreads as $d$-dimensional ball within the $d$-dimensional data space\n",
    "* as the shock wave front reaches a given data point, that point – imagined as a mass-spring system – begins to oscillate due to energy transfer\n",
    "* in result we hear a spherical scan of the data set starting from the location of excitation\n",
    "* The stereo position is determined from the relative location of the data point in the displayed projection relevative to the excitation center\n",
    "* model parameters are \n",
    "  * the shock wave velocity, \n",
    "  * the global level\n",
    "  * the ring time, i.e. the 60 dB decay times in seconds for the mass-spring systems of each data point.\n",
    "  * and a mode: which is currently unused, but will later allow to select a task-specific model variation. For instance `\"kNN-entropy\"` shall use the entropy of class labels among the $k$ nearest neighbors of each data point as spring stiffness, resulting in higher-pitched tones for data points that do not find themselves in a homogeneous area. This allows for instance to detect/inspect class borders and class overlaps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# headers and imports for the demo\n",
    "import sonecules as sn\n",
    "from pya import Asig\n",
    "import pyamapping as pam\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# setup for matplotlib \n",
    "plt.rcParams[\"figure.figsize\"] = (8,3)\n",
    "%matplotlib widget\n",
    "\n",
    "# start sonecules (with default backend sc3nb, aka sc3)\n",
    "sn.startup()\n",
    "ctx = sn.gcc()  # get the context as ctx\n",
    "ctx.enable_realtime();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load data sets used for the demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ../data/prepare-data.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(data=penguins_df, hue=\"species\", height=1.2);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = dataframes['penguins']\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Usage Demo for the Data Sonogram Model-Based Sonification Sonecule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sonecules.triggerson import DataSonogramMBS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code cell shows everything needed \n",
    "- to create the sonecule with data, \n",
    "- to reset the auditory canvas (aka timeline)\n",
    "- to start the playback at a given rate\n",
    "- to plot the timeline."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After executing the following line, click at any location in the plot with the left Mouse button (tap the track pad).\n",
    "The sonification starts with a noisy transient to indicate the exact moment in time when the shock wave started.\n",
    "This is followed by the sound of all "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dsg = DataSonogramMBS(penguins_df, x=\"flipper_length_mm\", y=\"bill_length_mm\", label=\"species\", rtime=1).start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# here a GUI to control the parameters - continue clicking in the plot\n",
    "def dsg_gui(rtime=0.5, max_duration=3, level=-6, trigger_sound=True):\n",
    "    dsg.rtime, dsg.max_duration, dsg.level, dsg.play_trigger_sound = rtime, max_duration, level, trigger_sound\n",
    "\n",
    "from ipywidgets import interactive\n",
    "interactive(dsg_gui, rtime=(0.05,5, 0.01), max_duration=(0.2, 10, 0.1), level=(-40, 10, 1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dsg._latency = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dsg.play_trigger_sound "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can disable the trigger sound and continue to click in the above plot without noise sample\n",
    "dsg.play_trigger_sound = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code Template"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code snippets are intended for copy & paste to your notebooks, to facilitate getting your data sonified\n",
    "using this sonecule.\n",
    "* It is assumed that your data is stored in an Asig dasig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sonecules.triggerson import DataSonogramMBS\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# load your multi-channel data into data frame: here 400 points in 4 clusters\n",
    "data = np.random.randn(400, 4) * np.tile(np.linspace(1, 0.2, 400), (4, 1)).T\n",
    "data[:100,:]    += np.tile([2,2,0,0],(100,1))\n",
    "data[100:200,:] += np.tile([1,4.5,0,0],(100,1))\n",
    "data[200:300,:] += np.tile([3,4.5,0,0],(100,1))\n",
    "data[:, 2] = 0; data[100:200,2] = 1; data[200:,2] = 2; data[300:,2] = 3\n",
    "df = pd.DataFrame(data, columns=[0,1,2,3])\n",
    "\n",
    "# enable realtims sonification\n",
    "ctx.enable_realtime()\n",
    "\n",
    "# create the model and GUI -> then click in the plot\n",
    "dsg = DataSonogramMBS(df, x=0, y=1, label=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now control parameters such as ring time or maximal duration \n",
    "dsg.rtime = 6.5 \n",
    "dsg.max_duration = 3\n",
    "dsg.level=-18\n",
    "dsg.play_trigger_sound = False\n",
    "# keep on clicking in the plot with new settings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# here a GUI to control the parameters\n",
    "def dsg_gui(rtime=0.5, max_duration=3, level=-6, trigger_sound=True):\n",
    "    dsg.rtime, dsg.max_duration, dsg.level, dsg.play_trigger_sound = rtime, max_duration, level, trigger_sound\n",
    "\n",
    "from ipywidgets import interactive\n",
    "interactive(dsg_gui, rtime=(0.05,5, 0.01), max_duration=(0.2, 10, 0.1), level=(-40, 10, 1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ctx.close()"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 2
}
